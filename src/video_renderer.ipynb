{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13901047,"sourceType":"datasetVersion","datasetId":8772791},{"sourceId":13944790,"sourceType":"datasetVersion","datasetId":8887660},{"sourceId":13945008,"sourceType":"datasetVersion","datasetId":8887825},{"sourceId":13945934,"sourceType":"datasetVersion","datasetId":8888504},{"sourceId":13946024,"sourceType":"datasetVersion","datasetId":8888566},{"sourceId":13946834,"sourceType":"datasetVersion","datasetId":8889200},{"sourceId":13947875,"sourceType":"datasetVersion","datasetId":8889943}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix dependencies by pinning numpy to <2.0 and reinstalling critical packages\nimport subprocess\nimport sys\n\ndef install_packages():\n    packages = [\n        \"numpy<2.0\",           # Downgrade numpy to 1.x to fix SciPy/TensorFlow compatibility\n        \"scipy\",               # Ensure SciPy is consistent with the numpy version\n        \"open3d\",\n        \"opencv-python\",\n        \"plyfile\",\n        \"gsplat\"\n    ]\n    \n    # Construct the pip install command\n    # Added --no-cache-dir to prevent issues with cached broken builds\n    command = [sys.executable, \"-m\", \"pip\", \"install\"] + packages + [\"--upgrade\", \"--no-cache-dir\"]\n    \n    print(\"Fixing dependencies... This may take a minute.\")\n    try:\n        subprocess.check_call(command)\n        print(\"Successfully fixed dependencies.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error during installation: {e}\")\n\ninstall_packages()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T16:08:13.255199Z","iopub.execute_input":"2025-12-01T16:08:13.255592Z","iopub.status.idle":"2025-12-01T16:08:18.091707Z","shell.execute_reply.started":"2025-12-01T16:08:13.255573Z","shell.execute_reply":"2025-12-01T16:08:18.090916Z"}},"outputs":[{"name":"stdout","text":"Fixing dependencies... This may take a minute.\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.3)\nRequirement already satisfied: open3d in /usr/local/lib/python3.11/dist-packages (0.19.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nCollecting opencv-python\n  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: plyfile in /usr/local/lib/python3.11/dist-packages (1.1.3)\nRequirement already satisfied: gsplat in /usr/local/lib/python3.11/dist-packages (1.5.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2.4.1)\nRequirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.3.0)\nRequirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\nRequirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\nRequirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\nRequirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from open3d) (1.7.1)\nRequirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.5)\nRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from open3d) (2.4.0)\nRequirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (11.3.0)\nRequirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.7.2)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.3)\nRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.3)\nRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\nRequirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from open3d) (0.9.9)\nINFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from gsplat) (1.13.0)\nRequirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from gsplat) (0.3.3)\nRequirement already satisfied: rich>=12 in /usr/local/lib/python3.11/dist-packages (from gsplat) (14.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from gsplat) (2.6.0+cu124)\nRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (4.15.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (2.32.5)\nRequirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.4.2)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.3.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.3)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.3)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.15)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (2.9.0.post0)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.25.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->gsplat) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->gsplat) (2.19.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\nRequirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping->gsplat) (0.1.7)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0) (2024.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (3.20.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (3.5)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->gsplat) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->gsplat) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0) (2024.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.26.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.5.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12->gsplat) (0.1.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2025.10.5)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\nSuccessfully fixed dependencies.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport os\nimport time\nimport scipy\nimport scipy.ndimage\nimport heapq\nimport math\nimport sys\nimport subprocess\nfrom scipy.ndimage import map_coordinates, label\nfrom scipy.interpolate import splprep, splev, interp1d\nfrom scipy.spatial.distance import cdist\nfrom scipy.spatial.transform import Rotation as R\n\nprint(\"Starting initialization and imports...\")\n\n# ====================================================================================\n# 0. Dependencies Imports and Checks\n# ====================================================================================\n\ntry:\n    import torch\n    TORCH_AVAILABLE = True\nexcept ImportError:\n    print(\"WARNING: Torch not available.\")\n    TORCH_AVAILABLE = False\n    torch = None\n\ntry:\n    import open3d as o3d\nexcept ImportError:\n    print(\"ERROR: Open3D not found. Ensure installation cell ran successfully.\")\n    o3d = None\n\ntry:\n    from plyfile import PlyData\nexcept ImportError:\n    print(\"ERROR: Plyfile not found.\")\n    PlyData = None\n\ntry:\n    import matplotlib.pyplot as plt\nexcept ImportError:\n    plt = None\n\ntry:\n    import cv2\nexcept ImportError:\n    cv2 = None\n\nGSPLAT_AVAILABLE = False\nif TORCH_AVAILABLE:\n    try:\n        import gsplat\n        GSPLAT_AVAILABLE = True\n    except ImportError:\n        print(\"INFO: gsplat not found.\")\n    except Exception as e:\n        print(f\"INFO: gsplat import issue: {e}.\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:08:18.092579Z","iopub.execute_input":"2025-12-01T16:08:18.092873Z","iopub.status.idle":"2025-12-01T16:08:21.614953Z","shell.execute_reply.started":"2025-12-01T16:08:18.092849Z","shell.execute_reply":"2025-12-01T16:08:21.614348Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Starting initialization and imports...\nJupyter environment detected. Enabling Open3D WebVisualizer.\n[Open3D INFO] WebRTC GUI backend enabled.\n[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ====================================================================================\n# 1. Global Configuration (UPDATED)\n# ====================================================================================\nclass Config:\n    # --- General Parameters ---\n    # Probably will need to change paths\n    INPUT_PLY_PATH = \"/kaggle/input/ply-scenes/input-data/outdoor-drone_exported.ply\"\n    OUTPUT_DIR = \"./output_results\"\n    JSON_PATH = \"/kaggle/input/drone-path-v3/planned_path.json\" \n\n    # Determine primary compute device\n    DEVICE = None\n    if TORCH_AVAILABLE and torch:\n        if torch.cuda.is_available():\n            DEVICE = torch.device(\"cuda:0\")\n        else:\n            DEVICE = torch.device(\"cpu\")\n\n    # --- Stage 1 Parameters (Geometry) ---\n    OPACITY_THRESHOLD = 0.05\n    SOR_NB_NEIGHBORS = 30\n    SOR_STD_RATIO = 2.5\n    TARGET_VOXEL_RESOLUTION = 300\n\n    # --- Stage 2 Parameters (Navigation Field) (UPDATED) ---\n    CLOSING_RADIUS_VOXELS = 2\n    # FIX: Adjusted safety radii for better indoor navigation balance.\n    R_SAFE_PLANNING_METERS = 0.40  # (was 0.8)\n    R_SAFE_MINIMUM_METERS = 0.15\n\n    # --- Stage 3 Parameters (Coverage) ---\n    TARGET_COVERAGE_RATIO = 0.85\n    MAX_WAYPOINTS = 12\n    CANDIDATE_SAMPLING_STRIDE = 5 \n    TARGET_DOWNSAMPLE_VOXEL_FACTOR = 3.5\n    RAY_OFFSET = 0.01\n\n    # --- Stage 4 Parameters (Path Planning) ---\n    TARGET_AVERAGE_SPEED = 1.2 # m/s\n    VIDEO_FPS = 60\n    INITIAL_SMOOTHING_FACTOR_RATIO = 2.0\n    MIN_SMOOTHING_FACTOR_RATIO = 0.001\n    SMOOTHING_REDUCTION_FACTOR = 0.5\n    COLLISION_CHECK_DENSITY = 100\n\n    # --- Stage 5 Parameters (Rendering) ---\n    # Global Up Vector: This will be dynamically updated in Stage 1.6.\n    GLOBAL_UP_VECTOR = np.array([0, 0, 1], dtype=np.float32) # Default fallback\n    GIMBAL_SMOOTHING_SIGMA = 15.0\n    RENDER_WIDTH = 1280\n    RENDER_HEIGHT = 720\n    FOV_Y_DEGREES = 60.0\n    NEAR_PLANE = 0.01\n    FAR_PLANE = 100.0\n\n# Initialize O3D_DEVICE\nConfig.O3D_DEVICE = None\nif o3d and hasattr(o3d, 'core'):\n    try:\n        if Config.DEVICE and \"cuda\" in str(Config.DEVICE):\n             Config.O3D_DEVICE = o3d.core.Device(\"CUDA:0\")\n        else:\n            Config.O3D_DEVICE = o3d.core.Device(\"CPU:0\")\n    except Exception:\n        Config.O3D_DEVICE = o3d.core.Device(\"CPU:0\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:09:05.839991Z","iopub.execute_input":"2025-12-01T16:09:05.840490Z","iopub.status.idle":"2025-12-01T16:09:05.847493Z","shell.execute_reply.started":"2025-12-01T16:09:05.840464Z","shell.execute_reply":"2025-12-01T16:09:05.846771Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ====================================================================================\n# 2. Global Variables (Inter-Stage Communication)\n# ====================================================================================\nSTAGE1_PCD = None; STAGE1_VOXEL_GRID = None; STAGE1_VOXEL_SIZE = 0.0; STAGE1_SCENE_CENTER = np.array([0.0, 0.0, 0.0])\nSTAGE4_FINAL_TRAJECTORY = None; STAGE4_TIMESTAMPS = None\nSTAGE5_CAMERA_POSES_C2W_ORIGINAL = None\n","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:08:21.625732Z","iopub.execute_input":"2025-12-01T16:08:21.625964Z","iopub.status.idle":"2025-12-01T16:08:21.639667Z","shell.execute_reply.started":"2025-12-01T16:08:21.625946Z","shell.execute_reply":"2025-12-01T16:08:21.638930Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ====================================================================================\n# 3. Utility Functions\n# ====================================================================================\ndef print_environment_info():\n    print(\"--- Environment Info ---\")\n    if TORCH_AVAILABLE and torch:\n        print(f\"Compute Device: {Config.DEVICE}\")\n    if Config.O3D_DEVICE: print(f\"Open3D Tensor Device: {Config.O3D_DEVICE}\")\n    print(f\"GSplat Available: {GSPLAT_AVAILABLE}\")\n    print(\"------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:09:05.848262Z","iopub.execute_input":"2025-12-01T16:09:05.848442Z","iopub.status.idle":"2025-12-01T16:09:05.860705Z","shell.execute_reply.started":"2025-12-01T16:09:05.848430Z","shell.execute_reply":"2025-12-01T16:09:05.860038Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ====================================================================================\n# 4. Stage 1: Loading and Geometry Analysis (UPDATED with Orientation Analysis)\n# ====================================================================================\n\ndef load_and_filter_ply(ply_path, opacity_threshold):\n    # (Implementation remains similar to original)\n    print(f\"\\n--- Step 1.1: Loading PLY file from {ply_path} ---\")\n    if o3d is None or PlyData is None: return np.array([])\n    if not os.path.exists(ply_path):\n        print(\"ERROR: File not found.\"); return np.array([])\n\n    start_time = time.time()\n    try:\n        plydata = PlyData.read(ply_path)\n        vertex_data = plydata.elements[0]\n        coordinates = np.stack((vertex_data['x'], vertex_data['y'], vertex_data['z']), axis=-1)\n\n        if 'opacity' in vertex_data.data.dtype.names:\n            opacity = np.asarray(vertex_data['opacity'])\n            mask = opacity >= opacity_threshold\n            filtered_coordinates = coordinates[mask]\n        else:\n            filtered_coordinates = coordinates\n\n        print(f\"Loaded {len(coordinates)} points. Filtered to {len(filtered_coordinates)}.\")\n        print(f\"Step 1.1 completed in {time.time() - start_time:.2f} seconds.\")\n        return filtered_coordinates\n    except Exception as e:\n        print(f\"ERROR: Failed to read PLY. Error: {e}.\"); return np.array([])\n\ndef create_and_clean_pcd(coordinates, sor_nb_neighbors, sor_std_ratio):\n    # (Implementation remains similar to original)\n    print(\"\\n--- Step 1.2 & 1.3: Creating Open3D PCD and Cleaning (SOR) ---\")\n    if len(coordinates) == 0 or o3d is None: return None\n    start_time = time.time()\n    pcd = o3d.geometry.PointCloud()\n    pcd.points = o3d.utility.Vector3dVector(coordinates)\n    cleaned_pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=sor_nb_neighbors, std_ratio=sor_std_ratio)\n    print(f\"Points remaining: {len(cleaned_pcd.points)}\")\n    print(f\"Step 1.2 & 1.3 completed in {time.time() - start_time:.2f} seconds.\")\n    return cleaned_pcd\n\ndef normalize_scene(pcd):\n    # (Implementation remains similar to original)\n    print(\"\\n--- Step 1.4: Normalization (Centering) ---\")\n    if pcd is None: return None, np.array([0.0, 0.0, 0.0])\n    center = pcd.get_center()\n    pcd.translate(-center)\n    return pcd, center\n\ndef adaptive_voxelization(pcd, target_resolution):\n    # (Implementation remains similar to original)\n    print(\"\\n--- Step 1.5: Adaptive Voxelization ---\")\n    if pcd is None: return None, 0.0\n    start_time = time.time()\n    extent = pcd.get_axis_aligned_bounding_box().get_extent()\n    longest_axis_length = np.max(extent)\n\n    if longest_axis_length < 1e-6:\n        voxel_size = 0.1\n    else:\n        voxel_size = longest_axis_length / target_resolution\n\n    try:\n        voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=voxel_size)\n    except Exception as e:\n        print(f\"ERROR: Voxelization failed: {e}\"); return None, voxel_size\n\n    print(f\"Calculated adaptive voxel size: {voxel_size:.4f}\")\n    print(f\"Step 1.5 completed in {time.time() - start_time:.2f} seconds.\")\n    return voxel_grid, voxel_size\n\ndef analyze_scene_orientation(pcd, voxel_size):\n    \"\"\"\n    (NEW) Analyzes the point cloud normals to determine the dominant 'Up' vector automatically.\n    \"\"\"\n    print(\"\\n--- Step 1.6 (NEW): Analyzing Scene Orientation (Up-Vector) ---\")\n    if pcd is None or len(pcd.points) < 100:\n        return Config.GLOBAL_UP_VECTOR\n\n    start_time = time.time()\n\n    # 1. Downsample and Estimate Normals\n    analysis_pcd = pcd.voxel_down_sample(voxel_size=voxel_size * 1.5)\n    radius = voxel_size * 3.0\n    try:\n        analysis_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=30))\n        analysis_pcd.orient_normals_consistent_tangent_plane(k=15)\n    except Exception as e:\n        print(f\"WARNING: Normal estimation failed. Falling back to default Up-Vector.\")\n        return Config.GLOBAL_UP_VECTOR\n\n    normals = np.asarray(analysis_pcd.normals)\n\n    # 2. Analyze Normal Distribution (Histogram approach)\n    BINS = 50\n    hists = [np.histogram(normals[:, i], bins=BINS, range=(-1, 1))[0] for i in range(3)]\n\n    # Score based on peaks at the extremes (floors/ceilings)\n    peak_width = BINS // 10\n    scores = [np.sum(h[:peak_width]) + np.sum(h[-peak_width:]) for h in hists]\n    dominant_axis_idx = np.argmax(scores)\n\n    # 3. Determine the Up direction (+ or -)\n    up_vector = np.zeros(3)\n    axis_names = [\"X\", \"Y\", \"Z\"]\n    print(f\"Dominant vertical axis detected: {axis_names[dominant_axis_idx]}\")\n\n    # Calculate the average direction of the dominant normals\n    dominant_normals = normals[np.abs(normals[:, dominant_axis_idx]) > 0.8, dominant_axis_idx]\n    mean_val = np.mean(dominant_normals) if len(dominant_normals) > 0 else 0\n\n    if mean_val > 0.05:\n        direction = 1\n    elif mean_val < -0.05:\n        direction = -1\n    else:\n        print(\"WARNING: Up direction is ambiguous. Falling back to default.\")\n        return Config.GLOBAL_UP_VECTOR\n\n    up_vector[dominant_axis_idx] = direction\n\n    print(f\"Successfully Detected Global Up-Vector: {up_vector}\")\n    print(f\"Step 1.6 completed in {time.time() - start_time:.2f} seconds.\")\n    return up_vector.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:09:05.861487Z","iopub.execute_input":"2025-12-01T16:09:05.861684Z","iopub.status.idle":"2025-12-01T16:09:05.876135Z","shell.execute_reply.started":"2025-12-01T16:09:05.861669Z","shell.execute_reply":"2025-12-01T16:09:05.875347Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ====================================================================================\n# Stage 5: Cinematic Orientation and Rendering (UPDATED with GAF)\n# ====================================================================================\n\ndef calculate_orientations_from_look_at(trajectory, look_at_targets, global_up_vector):\n    \"\"\"\n    Calculate camera orientations based on look_at targets.\n    The camera looks from each trajectory position towards the corresponding look_at target.\n    Adopts OpenCV convention: X=Right, Y=Down, Z=Forward.\n    \"\"\"\n    print(\"\\n--- Step 5.1: Calculating Camera Orientations from Look-At Targets ---\")\n    start_time = time.time()\n    \n    N = len(trajectory)\n    if N < 1:\n        return np.array([[[1, 0, 0], [0, 1, 0], [0, 0, 1]]])\n    \n    if look_at_targets is None or len(look_at_targets) != N:\n        print(\"WARNING: look_at_targets not provided or invalid, falling back to trajectory-based orientation\")\n        return calculate_base_orientations(trajectory, global_up_vector)\n    \n    # 1. Calculate Forward Vectors (Z-basis) from camera position to look_at target\n    Z_basis = look_at_targets - trajectory\n    \n    # 2. Normalize forward vectors\n    norms = np.linalg.norm(Z_basis, axis=1)\n    \n    # Handle cases where camera position equals look_at target\n    for i in range(N):\n        if norms[i] < 1e-6:\n            # Use trajectory tangent as fallback\n            if i < N - 1:\n                Z_basis[i] = trajectory[i + 1] - trajectory[i]\n            elif i > 0:\n                Z_basis[i] = trajectory[i] - trajectory[i - 1]\n            else:\n                Z_basis[i] = np.array([0, 0, 1], dtype=np.float32)\n            norms[i] = np.linalg.norm(Z_basis[i])\n    \n    # Normalize\n    valid_norms = norms > 1e-6\n    Z_basis[valid_norms] = Z_basis[valid_norms] / norms[valid_norms, np.newaxis]\n    \n    # 3. Calculate Right Vectors (X-basis) using Global Up\n    X_basis = np.cross(global_up_vector, Z_basis)\n    X_norms = np.linalg.norm(X_basis, axis=1)\n    \n    # 4. Handle Gimbal Lock\n    locked = X_norms < 1e-3\n    if np.any(locked):\n        for i in range(N):\n            if locked[i]:\n                if i > 0:\n                    X_basis[i] = X_basis[i-1]\n                else:\n                    arbitrary_vec = np.array([1, 0, 0], dtype=np.float32)\n                    if abs(np.dot(arbitrary_vec, Z_basis[i])) > 0.99:\n                        arbitrary_vec = np.array([0, 1, 0], dtype=np.float32)\n                    X_basis[i] = np.cross(Z_basis[i], arbitrary_vec)\n    \n    # Normalize X_basis\n    X_norms = np.linalg.norm(X_basis, axis=1)\n    valid_X_norms = X_norms > 1e-6\n    if np.all(valid_X_norms):\n        X_basis = X_basis / X_norms[:, np.newaxis]\n    else:\n        X_basis[valid_X_norms] = X_basis[valid_X_norms] / X_norms[valid_X_norms, np.newaxis]\n    \n    # 5. Calculate True Up Vectors\n    Up_basis = np.cross(Z_basis, X_basis)\n    \n    # 6. Ensure Up vectors point upward\n    for i in range(N):\n        if np.dot(Up_basis[i], global_up_vector) < 0:\n            X_basis[i] = -X_basis[i]\n            Up_basis[i] = -Up_basis[i]\n    \n    # 7. Enforce continuity\n    for i in range(1, N):\n        if np.dot(X_basis[i], X_basis[i-1]) < 0:\n            X_basis[i] = -X_basis[i]\n            Up_basis[i] = -Up_basis[i]\n    \n    # 8. Assemble Final Rotation Matrices (C2W) for OpenCV\n    rotation_matrices = np.zeros((N, 3, 3))\n    rotation_matrices[:, :, 0] = X_basis\n    rotation_matrices[:, :, 1] = -Up_basis\n    rotation_matrices[:, :, 2] = Z_basis\n    \n    print(f\"Step 5.1 completed in {time.time() - start_time:.2f} seconds.\")\n    return rotation_matrices\n\ndef calculate_base_orientations(trajectory, global_up_vector):\n    \"\"\"\n    (UPDATED) Step 5.1: Calculates orientations using Globally Aligned Frames (GAF).\n    Replaces the previous Parallel Transport (RMF) method.\n    Ensures the horizon remains level relative to the global_up_vector.\n    Adopts OpenCV convention: X=Right, Y=Down, Z=Forward.\n    \"\"\"\n    print(\"\\n--- Step 5.1 (UPDATED): Calculating Globally Aligned Orientations (GAF) ---\")\n    start_time = time.time()\n\n    N = len(trajectory)\n    if N < 2:\n        return np.array([[[1, 0, 0], [0, 1, 0], [0, 0, 1]]])\n\n    # 1. Calculate Tangents (Forward Vectors = Z-basis)\n    Z_basis = np.zeros((N, 3))\n    # Central differences for smoothness\n    Z_basis[1:-1] = trajectory[2:] - trajectory[:-2]\n    Z_basis[0] = trajectory[1] - trajectory[0]\n    Z_basis[-1] = trajectory[-1] - trajectory[-2]\n\n    # 2. Normalize and handle zero velocity\n    norms = np.linalg.norm(Z_basis, axis=1)\n    # If the camera stops, maintain the previous direction\n    for i in range(1, N):\n        if norms[i] < 1e-6:\n            Z_basis[i] = Z_basis[i-1]\n            norms[i] = norms[i-1]\n\n    if np.all(norms < 1e-6):\n        return np.array([[[1, 0, 0], [0, 1, 0], [0, 0, 1]]] * N)\n\n    # Apply normalization where norms are valid\n    valid_norms = norms > 1e-6\n    Z_basis[valid_norms] = Z_basis[valid_norms] / norms[valid_norms, np.newaxis]\n\n    # 3. Calculate Right Vectors (X-basis) using Global Up Anchor\n    # X = Cross(Global_Up, Z). This is the core of GAF.\n    X_basis = np.cross(global_up_vector, Z_basis)\n    X_norms = np.linalg.norm(X_basis, axis=1)\n\n    # 4. Handle Gimbal Lock (Camera looking straight up or down)\n    locked = X_norms < 1e-3\n    if np.any(locked):\n        # Where locked, reuse the X_basis from the previous frame for stability.\n        for i in range(N):\n            if locked[i]:\n                if i > 0:\n                    X_basis[i] = X_basis[i-1]\n                else:\n                    # Handle lock at the start: find an arbitrary orthogonal vector\n                    arbitrary_vec = np.array([1, 0, 0], dtype=np.float32)\n                    if abs(np.dot(arbitrary_vec, Z_basis[i])) > 0.99:\n                            arbitrary_vec = np.array([0, 1, 0], dtype=np.float32)\n                    # Cross product to find a valid X basis (ensure it's orthogonal to Z)\n                    X_basis[i] = np.cross(Z_basis[i], arbitrary_vec)\n\n\n    # Normalize X_basis again\n    X_norms = np.linalg.norm(X_basis, axis=1)\n    valid_X_norms = X_norms > 1e-6\n    # Ensure division by zero is handled if any norms are still invalid\n    if np.all(valid_X_norms):\n         X_basis = X_basis / X_norms[:, np.newaxis]\n    else:\n         # Only normalize valid entries\n         X_basis[valid_X_norms] = X_basis[valid_X_norms] / X_norms[valid_X_norms, np.newaxis]\n\n    # 5. Calculate True Up Vectors\n    # True_Up = Cross(Z, X) - ensures orthogonality\n    Up_basis = np.cross(Z_basis, X_basis)\n    \n    # 6. Ensure Up vectors point generally upward (prevent flipping)\n    # Check if Up vector aligns with global up, flip if pointing down\n    for i in range(N):\n        if np.dot(Up_basis[i], global_up_vector) < 0:\n            # Flip both X and Up to maintain right-handed coordinate system\n            X_basis[i] = -X_basis[i]\n            Up_basis[i] = -Up_basis[i]\n    \n    # 7. Enforce continuity - prevent sudden flips between frames\n    for i in range(1, N):\n        # Check if X basis flipped relative to previous frame\n        if np.dot(X_basis[i], X_basis[i-1]) < 0:\n            X_basis[i] = -X_basis[i]\n            Up_basis[i] = -Up_basis[i]\n\n    # 8. Assemble Final Rotation Matrices (C2W) for OpenCV\n    rotation_matrices = np.zeros((N, 3, 3))\n    rotation_matrices[:, :, 0] = X_basis      # Right\n    rotation_matrices[:, :, 1] = -Up_basis    # Down (OpenCV convention)\n    rotation_matrices[:, :, 2] = Z_basis      # Forward\n\n    print(f\"Step 5.1 completed in {time.time() - start_time:.2f} seconds.\")\n    return rotation_matrices\n\ndef apply_camera_roll(rotation_matrices, roll_degrees):\n    \"\"\"\n    Apply a roll rotation to camera orientations.\n    Roll is rotation around the forward (Z) axis.\n    Positive roll rotates the camera counter-clockwise when looking forward.\n    \n    Args:\n        rotation_matrices: Nx3x3 array of rotation matrices\n        roll_degrees: Roll angle in degrees (90 = rotate left, -90 = rotate right)\n    \n    Returns:\n        Rotated camera matrices\n    \"\"\"\n    print(f\"\\n--- Applying Camera Roll: {roll_degrees} degrees ---\")\n    \n    # Create roll rotation matrix around Z axis\n    roll_rad = np.deg2rad(roll_degrees)\n    cos_r = np.cos(roll_rad)\n    sin_r = np.sin(roll_rad)\n    \n    # Roll rotation matrix (rotation around Z axis)\n    roll_matrix = np.array([\n        [cos_r, -sin_r, 0],\n        [sin_r, cos_r, 0],\n        [0, 0, 1]\n    ], dtype=np.float32)\n    \n    # Apply roll to each rotation matrix\n    rolled_matrices = np.zeros_like(rotation_matrices)\n    for i in range(len(rotation_matrices)):\n        rolled_matrices[i] = rotation_matrices[i] @ roll_matrix\n    \n    return rolled_matrices\n\ndef smooth_orientations_gimbal(rotation_matrices, sigma):\n    # (Implementation remains the same)\n    print(f\"\\n--- Step 5.2 Smoothing (Sigma={sigma}) ---\")\n    N = len(rotation_matrices)\n    if N < 2 or sigma <= 0: return rotation_matrices\n\n    try:\n        quats = R.from_matrix(rotation_matrices).as_quat()\n    except: return rotation_matrices\n\n    # Ensure quaternion continuity (prevent flips)\n    for i in range(1, N):\n        if np.dot(quats[i], quats[i-1]) < 0: quats[i] = -quats[i]\n\n    # Apply Gaussian filter\n    smoothed_q = scipy.ndimage.gaussian_filter1d(quats, sigma=sigma, axis=0, mode='reflect')\n    # Normalize\n    norms = np.linalg.norm(smoothed_q, axis=1, keepdims=True)\n    smoothed_q /= (norms + 1e-8)\n    return R.from_quat(smoothed_q).as_matrix()\n\ndef assemble_camera_poses(trajectory, rotation_matrices, scene_center):\n    # (Implementation remains the same)\n    print(\"\\n--- 5.3 Assembling Poses ---\")\n    N = len(trajectory)\n    poses_norm = np.eye(4)[np.newaxis].repeat(N, axis=0)\n    poses_orig = np.eye(4)[np.newaxis].repeat(N, axis=0)\n    \n    poses_norm[:, :3, :3] = rotation_matrices; poses_norm[:, :3, 3] = trajectory\n    # Denormalize position for original scene coordinates\n    poses_orig[:, :3, :3] = rotation_matrices; poses_orig[:, :3, 3] = trajectory + scene_center\n    return poses_norm, poses_orig\n\ndef visualize_final_path(pcd, final_traj, output_dir):\n    # (Implementation simplified)\n    print(\"\\n--- 5.4 Saving Path Visualization ---\")\n    if o3d is None or pcd is None: return\n    \n    vis = o3d.geometry.PointCloud()\n    try:\n        # Downsample scene context\n        scene_vis = pcd.voxel_down_sample(0.1)\n        scene_vis.paint_uniform_color([0.7, 0.7, 0.7])\n        vis += scene_vis\n    except: pass\n    \n    if final_traj is not None:\n        p = o3d.geometry.PointCloud()\n        p.points = o3d.utility.Vector3dVector(final_traj)\n        p.paint_uniform_color([0, 1, 0]) # Green path\n        vis += p\n        \n    try:\n        os.makedirs(output_dir, exist_ok=True)\n        o3d.io.write_point_cloud(f\"{output_dir}/path_vis.ply\", vis)\n        print(f\"Saved {output_dir}/path_vis.ply\")\n    except: pass\n\n# --- ROBUST RENDERING LOGIC ---\n# (Implementation remains similar to original, robustified)\n\ndef load_full_ply_for_gsplat(path, device):\n    print(f\"Loading full PLY data for rendering from {path}...\", flush=True)\n    if not os.path.exists(path) or PlyData is None or torch is None: return None\n\n    try:\n        plydata = PlyData.read(path); v = plydata.elements[0]\n    except: return None\n\n    def to_ten(x):\n        t = torch.tensor(x, dtype=torch.float32, device=device)\n        if torch.isnan(t).any(): t = torch.nan_to_num(t)\n        return t.contiguous()\n\n    means = np.stack((v['x'], v['y'], v['z']), axis=-1); N = len(means)\n\n    # Gracefully handle potentially missing fields\n    try: opacities = v['opacity']\n    except: opacities = np.ones((N, 1))\n    try: scales = np.stack((v['scale_0'], v['scale_1'], v['scale_2']), axis=-1)\n    except: scales = np.full((N, 3), 0.01)\n    try: quats = np.stack((v['rot_0'], v['rot_1'], v['rot_2'], v['rot_3']), axis=-1)\n    except: quats = np.zeros((N, 4)); quats[:, 0] = 1.0\n    try: sh_dc = np.stack((v['f_dc_0'], v['f_dc_1'], v['f_dc_2']), axis=-1)\n    except: sh_dc = np.full((N, 3), 0.5)\n\n    # Handle SH Rest (Spherical Harmonics)\n    extra_names = sorted([p.name for p in v.properties if p.name.startswith('f_rest_')], key=lambda x: int(x.split('_')[-1]))\n    if len(extra_names) > 0:\n        sh_rest = np.stack([v[n] for n in extra_names], axis=-1)\n        if sh_rest.shape[1] % 3 == 0:\n             sh_rest = sh_rest.reshape(N, sh_rest.shape[1] // 3, 3)\n             shs = np.concatenate((sh_dc[:, None, :], sh_rest), axis=1)\n        else: shs = sh_dc[:, None, :]\n    else: shs = sh_dc[:, None, :]\n\n    print(f\"Loaded {N} gaussians. SH shape: {shs.shape}\")\n    return {'means': to_ten(means), 'scales': to_ten(scales), 'quats': to_ten(quats),\n            'opacities': to_ten(opacities), 'shs': to_ten(shs)}\n\n\ndef render_video(poses, ply_path, config, output_dir):\n    print(\"\\n--- Step 5.5: Rendering Video (GSplat Rasterization) ---\", flush=True)\n\n    if cv2 is None or not GSPLAT_AVAILABLE or torch is None:\n        print(\"Error: Missing dependencies.\"); return\n\n    if not (torch.cuda.is_available() and config.DEVICE and \"cuda\" in str(config.DEVICE)):\n        print(\"Warning: CUDA not available/configured. Rendering requires GPU.\"); return\n\n    # 1. Load Data\n    with torch.no_grad():\n        g_data = load_full_ply_for_gsplat(ply_path, config.DEVICE)\n    if g_data is None: return\n\n    # 2. Determine SH Degree\n    K = g_data['shs'].shape[1]\n    try:\n        sh_degree = int(math.sqrt(K) - 1)\n        if (sh_degree + 1)**2 != K: sh_degree = 0\n    except: sh_degree = 0\n    print(f\"Detected SH Degree: {sh_degree} (K={K})\")\n\n    # 3. Setup Video Writer\n    H, W = config.RENDER_HEIGHT, config.RENDER_WIDTH\n    os.makedirs(output_dir, exist_ok=True)\n    video_path = os.path.join(output_dir, \"cinematic_tour.mp4\")\n\n    try:\n        writer = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), config.VIDEO_FPS, (W, H))\n    except: print(\"ERROR: Initializing VideoWriter failed.\"); return\n\n    # 4. Calculate Intrinsics\n    fov_y_rad = np.deg2rad(config.FOV_Y_DEGREES)\n    focal_length = H / (2.0 * np.tan(fov_y_rad / 2.0))\n    K_mat = torch.tensor([[focal_length, 0, W/2.0], [0, focal_length, H/2.0], [0, 0, 1]], device=config.DEVICE, dtype=torch.float32)\n\n    # Pre-process static attributes\n    with torch.no_grad():\n        means = g_data['means']\n        scales = torch.exp(g_data['scales'])\n        opacities = torch.sigmoid(g_data['opacities'])\n        quats = g_data['quats']\n        quats = quats / (quats.norm(dim=-1, keepdim=True) + 1e-8)\n        shs = g_data['shs']\n\n    # 5. Rendering Loop\n    start_time = time.time()\n    print(f\"Rendering {len(poses)} frames...\")\n    for i, c2w in enumerate(poses):\n        try:\n            with torch.no_grad():\n                c2w_torch = torch.tensor(c2w, dtype=torch.float32, device=config.DEVICE)\n                w2c = torch.inverse(c2w_torch)\n\n                render_output = gsplat.rasterization(\n                    means=means, quats=quats, scales=scales, opacities=opacities, colors=shs,\n                    viewmats=w2c.unsqueeze(0), Ks=K_mat.unsqueeze(0), width=W, height=H,\n                    sh_degree=sh_degree, packed=False\n                )\n\n                if isinstance(render_output, tuple):\n                    render_colors = render_output[0]\n                else:\n                    render_colors = render_output\n\n                img_tensor = render_colors[0].clamp(0, 1)\n                img_np = (img_tensor.cpu().numpy() * 255).astype(np.uint8)\n                img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n                writer.write(img_bgr)\n\n        except Exception as e:\n            print(f\"\\nCRITICAL Render Error at frame {i}: {e}\"); break\n\n        if i % 50 == 0 or i == len(poses) - 1:\n            elapsed = time.time() - start_time\n            fps = (i + 1) / (elapsed + 1e-6)\n            print(f\"\\rFrame {i+1}/{len(poses)}. Avg FPS: {fps:.2f}\", end=\"\", flush=True)\n\n    print(\"\\nRendering finished.\")\n    writer.release()\n\n    # Cleanup GPU memory\n    if torch:\n        del g_data, means, scales, opacities, quats, shs\n        if torch.cuda.is_available(): torch.cuda.empty_cache()\n\n    print(f\"Video saved: {video_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:09:05.878696Z","iopub.execute_input":"2025-12-01T16:09:05.879131Z","iopub.status.idle":"2025-12-01T16:09:05.917531Z","shell.execute_reply.started":"2025-12-01T16:09:05.879114Z","shell.execute_reply":"2025-12-01T16:09:05.916831Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ====================================================================================\n# 4. Main Pipeline Execution\n# ====================================================================================\n\ndef load_path_from_json(json_path):\n    \"\"\"\n    Load camera path from a JSON file.\n    Expected format: list of dicts with 'pos' and 'look_at' keys.\n    Returns trajectory positions and look_at targets (both Nx3 arrays).\n    \"\"\"\n    import json\n    print(f\"\\n--- Loading Path from {json_path} ---\")\n    \n    if not os.path.exists(json_path):\n        print(f\"ERROR: Path file not found at {json_path}\")\n        return None, None\n    \n    try:\n        with open(json_path, 'r') as f:\n            path_data = json.load(f)\n        \n        if not isinstance(path_data, list) or len(path_data) == 0:\n            print(\"ERROR: Invalid path data format\")\n            return None, None\n        \n        # Extract positions and look_at targets\n        positions = []\n        look_ats = []\n        for entry in path_data:\n            if 'pos' in entry:\n                positions.append(entry['pos'])\n            if 'look_at' in entry:\n                look_ats.append(entry['look_at'])\n        \n        if len(positions) == 0:\n            print(\"ERROR: No positions found in path data\")\n            return None, None\n        \n        trajectory = np.array(positions, dtype=np.float32)\n        look_at_targets = np.array(look_ats, dtype=np.float32) if len(look_ats) == len(positions) else None\n        \n        print(f\"Loaded {len(trajectory)} waypoints from JSON\")\n        \n        # Remove consecutive duplicate positions that could cause singular matrices\n        if len(trajectory) > 1:\n            unique_mask = np.ones(len(trajectory), dtype=bool)\n            for i in range(1, len(trajectory)):\n                if np.allclose(trajectory[i], trajectory[i-1], atol=1e-6):\n                    unique_mask[i] = False\n            \n            if not np.all(unique_mask):\n                trajectory = trajectory[unique_mask]\n                if look_at_targets is not None:\n                    look_at_targets = look_at_targets[unique_mask]\n                print(f\"Removed {np.sum(~unique_mask)} duplicate positions. Final count: {len(trajectory)}\")\n        \n        return trajectory, look_at_targets\n        \n    except Exception as e:\n        print(f\"ERROR loading path: {e}\")\n        return None, None\n\ndef interpolate_path(waypoints, look_at_targets=None, step_size=0.1):\n    \"\"\"\n    Interpolate waypoints and look_at targets to create a smooth path with intermediate points.\n    \n    Args:\n        waypoints: Nx3 array of waypoint positions\n        look_at_targets: Nx3 array of look_at target positions (optional)\n        step_size: Maximum distance between consecutive points in the output\n    \n    Returns:\n        Interpolated positions and look_at targets (if provided)\n    \"\"\"\n    if len(waypoints) < 2:\n        return waypoints, look_at_targets\n    \n    print(f\"\\n--- Interpolating Path (step_size={step_size}) ---\")\n    interpolated_positions = []\n    interpolated_look_ats = [] if look_at_targets is not None else None\n    \n    for i in range(len(waypoints) - 1):\n        start_pos = waypoints[i]\n        end_pos = waypoints[i + 1]\n        \n        # Calculate distance between waypoints\n        distance = np.linalg.norm(end_pos - start_pos)\n        \n        # Calculate number of intermediate points needed\n        num_steps = max(1, int(np.ceil(distance / step_size)))\n        \n        # Create interpolated points (excluding the end point to avoid duplicates)\n        for j in range(num_steps):\n            t = j / num_steps\n            pos = start_pos * (1 - t) + end_pos * t\n            interpolated_positions.append(pos)\n            \n            # Interpolate look_at targets as well\n            if look_at_targets is not None:\n                start_look = look_at_targets[i]\n                end_look = look_at_targets[i + 1]\n                look = start_look * (1 - t) + end_look * t\n                interpolated_look_ats.append(look)\n    \n    # Add the final point\n    interpolated_positions.append(waypoints[-1])\n    if look_at_targets is not None:\n        interpolated_look_ats.append(look_at_targets[-1])\n    \n    interpolated_path = np.array(interpolated_positions, dtype=np.float32)\n    interpolated_look = np.array(interpolated_look_ats, dtype=np.float32) if interpolated_look_ats else None\n    \n    print(f\"Interpolated {len(waypoints)} waypoints to {len(interpolated_path)} points\")\n    \n    return interpolated_path, interpolated_look\n\ndef load_existing_path_pipeline(json_path=Config.JSON_PATH, interpolation_step=0.1):\n    \"\"\"\n    Load an existing path from JSON and perform minimal scene setup for rendering.\n    \n    Args:\n        json_path: Path to the JSON file containing waypoints\n        interpolation_step: Step size for path interpolation (smaller = smoother)\n    \"\"\"\n    global STAGE1_PCD, STAGE1_VOXEL_GRID, STAGE1_VOXEL_SIZE, STAGE1_SCENE_CENTER\n    global STAGE4_FINAL_TRAJECTORY, STAGE4_TIMESTAMPS, STAGE4_LOOK_AT_TARGETS\n\n    print(\"\\n===========================================\")\n    print(\"   LOADING EXISTING PATH FROM JSON        \")\n    print(\"===========================================\")\n    print_environment_info()\n    pipeline_start_time = time.time()\n\n    if o3d is None:\n        print(\">>> Pipeline aborted: Open3D is required.\"); return\n\n    # --- STAGE 1: Minimal Geometry Analysis (needed for scene center and orientation) ---\n    coords = load_and_filter_ply(Config.INPUT_PLY_PATH, Config.OPACITY_THRESHOLD)\n    if len(coords) == 0: return\n\n    pcd = create_and_clean_pcd(coords, Config.SOR_NB_NEIGHBORS, Config.SOR_STD_RATIO)\n    if pcd is None: return\n\n    STAGE1_PCD, STAGE1_SCENE_CENTER = normalize_scene(pcd)\n\n    STAGE1_VOXEL_GRID, STAGE1_VOXEL_SIZE = adaptive_voxelization(STAGE1_PCD, Config.TARGET_VOXEL_RESOLUTION)\n    if STAGE1_VOXEL_GRID is None: return\n\n    # Analyze Scene Orientation\n    detected_up_vector = analyze_scene_orientation(STAGE1_PCD, STAGE1_VOXEL_SIZE)\n    Config.GLOBAL_UP_VECTOR = detected_up_vector\n\n    # --- LOAD PATH FROM JSON ---\n    loaded_trajectory, loaded_look_ats = load_path_from_json(json_path)\n    if loaded_trajectory is None:\n        print(\">>> Failed to load path from JSON\"); return\n    \n    if len(loaded_trajectory) < 2:\n        print(\">>> ERROR: Path must have at least 2 waypoints\"); return\n    \n    # --- INTERPOLATE PATH ---\n    if interpolation_step > 0:\n        loaded_trajectory, loaded_look_ats = interpolate_path(loaded_trajectory, loaded_look_ats, step_size=interpolation_step)\n    \n    # The loaded path is already in world coordinates, so we need to normalize it\n    # by subtracting the scene center (same as done in normalize_scene)\n    normalized_trajectory = loaded_trajectory - STAGE1_SCENE_CENTER\n    normalized_look_ats = loaded_look_ats - STAGE1_SCENE_CENTER if loaded_look_ats is not None else None\n    \n    # Validate that normalization didn't create degenerate positions\n    print(f\"\\nPath statistics after normalization:\")\n    print(f\"  Min position: {np.min(normalized_trajectory, axis=0)}\")\n    print(f\"  Max position: {np.max(normalized_trajectory, axis=0)}\")\n    print(f\"  Mean position: {np.mean(normalized_trajectory, axis=0)}\")\n    \n    # Check for any remaining issues\n    deltas = np.linalg.norm(np.diff(normalized_trajectory, axis=0), axis=1)\n    min_delta = np.min(deltas)\n    max_delta = np.max(deltas)\n    print(f\"  Minimum step size: {min_delta:.6f}\")\n    print(f\"  Maximum step size: {max_delta:.6f}\")\n    \n    if min_delta < 1e-6:\n        print(\"WARNING: Very small steps detected in trajectory\")\n    \n    STAGE4_FINAL_TRAJECTORY = normalized_trajectory\n    STAGE4_LOOK_AT_TARGETS = normalized_look_ats\n    \n    # Create timestamps based on the trajectory length\n    num_frames = len(STAGE4_FINAL_TRAJECTORY)\n    duration = num_frames / Config.VIDEO_FPS\n    STAGE4_TIMESTAMPS = np.linspace(0, duration, num_frames)\n    \n    print(f\"\\n>>> Path Loading Completed Successfully in {time.time() - pipeline_start_time:.2f} seconds.\")\n    print(f\"Trajectory has {len(STAGE4_FINAL_TRAJECTORY)} waypoints\")\n    if STAGE4_LOOK_AT_TARGETS is not None:\n        print(f\"Look-at targets loaded: {len(STAGE4_LOOK_AT_TARGETS)} points\")\n    print(f\"Video duration: {duration:.2f} seconds\")\n\ndef run_rendering_pipeline(camera_roll_degrees=180):\n    \"\"\"\n    Run the rendering pipeline with optional camera roll.\n    \n    Args:\n        camera_roll_degrees: Roll angle in degrees (90 = rotate left, -90 = rotate right, 0 = no rotation)\n    \"\"\"\n    global STAGE1_PCD, STAGE1_SCENE_CENTER\n    global STAGE4_FINAL_TRAJECTORY, STAGE4_LOOK_AT_TARGETS\n    global STAGE5_CAMERA_POSES_C2W_ORIGINAL\n\n    print(\"\\n===========================================\")\n    print(\"   RENDERING PIPELINE   \")\n    print(\"===========================================\")\n\n    if STAGE4_FINAL_TRAJECTORY is None:\n        print(\"ERROR: No trajectory found. Load path first.\"); return\n    \n    if len(STAGE4_FINAL_TRAJECTORY) < 2:\n        print(\"ERROR: Trajectory must have at least 2 waypoints.\"); return\n\n    # --- Calculate Orientations ---\n    print(f\"Using Detected Global Up Vector for Stabilization: {Config.GLOBAL_UP_VECTOR}\")\n    \n    # Debug: Check trajectory validity before orientation calculation\n    print(f\"\\nTrajectory validation:\")\n    print(f\"  Number of waypoints: {len(STAGE4_FINAL_TRAJECTORY)}\")\n    print(f\"  First waypoint: {STAGE4_FINAL_TRAJECTORY[0]}\")\n    print(f\"  Last waypoint: {STAGE4_FINAL_TRAJECTORY[-1]}\")\n    if STAGE4_LOOK_AT_TARGETS is not None:\n        print(f\"  Look-at targets available: {len(STAGE4_LOOK_AT_TARGETS)} points\")\n        print(f\"  First look-at: {STAGE4_LOOK_AT_TARGETS[0]}\")\n        print(f\"  Last look-at: {STAGE4_LOOK_AT_TARGETS[-1]}\")\n    \n    # Calculate orientations using look_at targets if available\n    if STAGE4_LOOK_AT_TARGETS is not None:\n        rotations = calculate_orientations_from_look_at(STAGE4_FINAL_TRAJECTORY, STAGE4_LOOK_AT_TARGETS, Config.GLOBAL_UP_VECTOR)\n    else:\n        rotations = calculate_base_orientations(STAGE4_FINAL_TRAJECTORY, Config.GLOBAL_UP_VECTOR)\n\n    # Apply camera roll if specified\n    if camera_roll_degrees != 0:\n        rotations = apply_camera_roll(rotations, camera_roll_degrees)\n\n    # Smooth Orientations\n    smoothed_rotations = smooth_orientations_gimbal(rotations, Config.GIMBAL_SMOOTHING_SIGMA)\n    \n    # Assemble Poses\n    Poses_Norm, STAGE5_CAMERA_POSES_C2W_ORIGINAL = assemble_camera_poses(\n        STAGE4_FINAL_TRAJECTORY, smoothed_rotations, STAGE1_SCENE_CENTER\n    )\n    \n    # Debug: Check pose validity\n    print(f\"\\nPose validation:\")\n    print(f\"  Number of poses: {len(STAGE5_CAMERA_POSES_C2W_ORIGINAL)}\")\n    first_pose = STAGE5_CAMERA_POSES_C2W_ORIGINAL[0]\n    print(f\"  First pose determinant: {np.linalg.det(first_pose[:3, :3]):.6f}\")\n    print(f\"  First pose position: {first_pose[:3, 3]}\")\n    \n    # Check if any poses are singular\n    for i, pose in enumerate(STAGE5_CAMERA_POSES_C2W_ORIGINAL):\n        det = np.linalg.det(pose[:3, :3])\n        if abs(det) < 1e-6:\n            print(f\"WARNING: Pose {i} has near-zero determinant: {det}\")\n            if i < 5:\n                print(f\"  Pose {i}:\\n{pose}\")\n    \n    # Visualize Path Geometry\n    visualize_final_path(\n        STAGE1_PCD, STAGE4_FINAL_TRAJECTORY, Config.OUTPUT_DIR\n    )\n    \n    # Render Final Video\n    render_video(\n        STAGE5_CAMERA_POSES_C2W_ORIGINAL, Config.INPUT_PLY_PATH, Config, Config.OUTPUT_DIR\n    )\n    \n    print(\"\\n=== PIPELINE COMPLETED ===\")\n\n# Execute the pipeline\nif __name__ == \"__main__\":\n    # Check if the input file exists before starting\n    if not os.path.exists(Config.INPUT_PLY_PATH):\n        print(f\"CRITICAL ERROR: Input file not found at {Config.INPUT_PLY_PATH}\")\n        print(\"Please ensure the dataset is correctly linked in the environment.\")\n    else:\n        # Load existing path from JSON with interpolation\n        # interpolation_step: smaller values = smoother path (more frames)\n        load_existing_path_pipeline(Config.JSON_PATH, interpolation_step=0.1)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:18:26.932688Z","iopub.execute_input":"2025-12-01T16:18:26.932987Z","iopub.status.idle":"2025-12-01T16:18:38.429568Z","shell.execute_reply.started":"2025-12-01T16:18:26.932967Z","shell.execute_reply":"2025-12-01T16:18:38.428906Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n===========================================\n   LOADING EXISTING PATH FROM JSON        \n===========================================\n--- Environment Info ---\nCompute Device: cuda:0\nOpen3D Tensor Device: CUDA:0\nGSplat Available: True\n------------------------\n\n--- Step 1.1: Loading PLY file from /kaggle/input/ply-scenes/input-data/outdoor-drone_exported.ply ---\nLoaded 3185436 points. Filtered to 2962617.\nStep 1.1 completed in 0.16 seconds.\n\n--- Step 1.2 & 1.3: Creating Open3D PCD and Cleaning (SOR) ---\nPoints remaining: 2944436\nStep 1.2 & 1.3 completed in 10.96 seconds.\n\n--- Step 1.4: Normalization (Centering) ---\n\n--- Step 1.5: Adaptive Voxelization ---\nCalculated adaptive voxel size: 0.4010\nStep 1.5 completed in 0.11 seconds.\n\n--- Step 1.6 (NEW): Analyzing Scene Orientation (Up-Vector) ---\nDominant vertical axis detected: Y\nSuccessfully Detected Global Up-Vector: [0. 1. 0.]\nStep 1.6 completed in 0.17 seconds.\n\n--- Loading Path from /kaggle/input/drone-path-v3/planned_path.json ---\nLoaded 57 waypoints from JSON\nRemoved 1 duplicate positions. Final count: 56\n\n--- Interpolating Path (step_size=0.1) ---\nInterpolated 56 waypoints to 586 points\n\nPath statistics after normalization:\n  Min position: [-3.08361794  0.00924526  0.38874073]\n  Max position: [6.10434411 0.00924526 7.65846575]\n  Mean position: [-0.60755896  0.00924526  5.39846215]\n  Minimum step size: 0.090000\n  Maximum step size: 0.100000\n\n>>> Path Loading Completed Successfully in 11.47 seconds.\nTrajectory has 586 waypoints\nLook-at targets loaded: 586 points\nVideo duration: 9.77 seconds\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"run_rendering_pipeline()","metadata":{"execution":{"iopub.status.busy":"2025-12-01T16:18:38.430685Z","iopub.execute_input":"2025-12-01T16:18:38.430914Z","iopub.status.idle":"2025-12-01T16:19:09.344578Z","shell.execute_reply.started":"2025-12-01T16:18:38.430897Z","shell.execute_reply":"2025-12-01T16:19:09.343846Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n===========================================\n   RENDERING PIPELINE   \n===========================================\nUsing Detected Global Up Vector for Stabilization: [0. 1. 0.]\n\nTrajectory validation:\n  Number of waypoints: 586\n  First waypoint: [-0.4807203   0.00924526  0.38874073]\n  Last waypoint: [-2.57780291  0.00924526  7.075117  ]\n  Look-at targets available: 586 points\n  First look-at: [0.0192797  0.00924526 0.08874072]\n  Last look-at: [0.0192797  0.00924526 0.08874072]\n\n--- Step 5.1: Calculating Camera Orientations from Look-At Targets ---\nStep 5.1 completed in 0.00 seconds.\n\n--- Applying Camera Roll: 180 degrees ---\n\n--- Step 5.2 Smoothing (Sigma=15.0) ---\n\n--- 5.3 Assembling Poses ---\n\nPose validation:\n  Number of poses: 586\n  First pose determinant: -1.000000\n  First pose position: [-0.5         0.          0.30000001]\n\n--- 5.4 Saving Path Visualization ---\nSaved ./output_results/path_vis.ply\n\n--- Step 5.5: Rendering Video (GSplat Rasterization) ---\nLoading full PLY data for rendering from /kaggle/input/ply-scenes/input-data/outdoor-drone_exported.ply...\nLoaded 3185436 gaussians. SH shape: (3185436, 1, 3)\nDetected SH Degree: 0 (K=1)\nRendering 586 frames...\nFrame 586/586. Avg FPS: 19.26\nRendering finished.\nVideo saved: ./output_results/cinematic_tour.mp4\n\n=== PIPELINE COMPLETED ===\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}